# ============================================================
# æ–‡ä»¶è¯´æ˜: polling_loops_v2.py - ç‹¬ç«‹çš„ä¸‰é€Ÿè½®è¯¢æ¶æ„
# ============================================================
# åŠŸèƒ½:
#   1. DB1 å¼§æµå¼§å‹è½®è¯¢ (å¯å˜é€Ÿ: 5s/0.2s)
#   2. DB32 ä¼ æ„Ÿå™¨è½®è¯¢ (å›ºå®š: 5s)
#   3. DB30/DB41 çŠ¶æ€è½®è¯¢ (å›ºå®š: 5s, ä»…ç¼“å­˜)
# ============================================================
# è®¾è®¡åŸåˆ™:
#   - ä¸‰ä¸ªç‹¬ç«‹çš„ asyncio.Task
#   - è‡ªåŠ¨å¯åŠ¨ (æ— éœ€å‰ç«¯è§¦å‘)
#   - å¼€å§‹å†¶ç‚¼æ—¶åˆ‡æ¢ DB1 é€Ÿåº¦
# ============================================================
# ã€æ•°æ®åº“å†™å…¥è¯´æ˜ - è½®è¯¢æ¶æ„ã€‘
# ============================================================
# 1: DB1 å¼§æµå¼§å‹è½®è¯¢ (_db1_arc_polling_loop)
#    - è½®è¯¢é—´éš”: 5ç§’(é»˜è®¤) / 0.2ç§’(å†¶ç‚¼ä¸­)
#    - æ‰¹é‡å†™å…¥: 20æ¬¡è½®è¯¢åå†™å…¥ (4ç§’)
#    - å†™å…¥æ¡ä»¶: å¿…é¡»æœ‰æ‰¹æ¬¡å·(batch_code)ä¸”å†¶ç‚¼çŠ¶æ€ä¸ºrunning/paused
#    - æ•°æ®ç‚¹: å¼§æµ(3) + å¼§å‹(3) + è®¾å®šå€¼(3,ä»…å˜åŒ–) + æ­»åŒº(1,ä»…å˜åŒ–)
# ============================================================
# 2: DB32 ä¼ æ„Ÿå™¨è½®è¯¢ (_db32_sensor_polling_loop)
#    - è½®è¯¢é—´éš”: 0.5ç§’
#    - æ‰¹é‡å†™å…¥: 30æ¬¡è½®è¯¢åå†™å…¥ (15ç§’)
#    - å†™å…¥æ¡ä»¶: å¿…é¡»æœ‰æ‰¹æ¬¡å·(batch_code)ä¸”å†¶ç‚¼çŠ¶æ€ä¸ºrunning/paused
#    - æ•°æ®ç‚¹: ç”µææ·±åº¦(3) + å†·å´æ°´å‹åŠ›(2) + å†·å´æ°´æµé‡(2) + å†·å´æ°´ç´¯è®¡(2)
# ============================================================
# 3: æ–™ä»“é‡é‡è½®è¯¢ (ä¸DB32åŒæ­¥)
#    - è½®è¯¢é—´éš”: 0.5ç§’
#    - æ‰¹é‡å†™å…¥: 30æ¬¡è½®è¯¢åå†™å…¥ (15ç§’)
#    - å†™å…¥æ¡ä»¶: å¿…é¡»æœ‰æ‰¹æ¬¡å·(batch_code)ä¸”å†¶ç‚¼çŠ¶æ€ä¸ºrunning/paused
#    - æ•°æ®ç‚¹: å‡€é‡(1) + æŠ•æ–™ç´¯è®¡(1) + æŠ•æ–™çŠ¶æ€(1)
# ============================================================
# 4: DB30/DB41 çŠ¶æ€è½®è¯¢ (_status_polling_loop)
#    - è½®è¯¢é—´éš”: 5ç§’
#    - å†™å…¥: ä¸å†™å…¥æ•°æ®åº“ï¼Œä»…å†…å­˜ç¼“å­˜
#    - æ•°æ®ç‚¹: é€šä¿¡çŠ¶æ€ + æ•°æ®æœ‰æ•ˆæ€§çŠ¶æ€
# ============================================================

import asyncio
import traceback
from datetime import datetime, timezone
from typing import Optional

from backend.config import get_settings
from backend.plc.plc_manager import get_plc_manager
from loguru import logger

settings = get_settings()

# ============================================================
# å…¨å±€å˜é‡ (è½®è¯¢ä»»åŠ¡)
# ============================================================
_db1_task: Optional[asyncio.Task] = None
_db32_task: Optional[asyncio.Task] = None
_status_task: Optional[asyncio.Task] = None

# è¿è¡Œæ ‡å¿—
_db1_running = False
_db32_running = False
_status_running = False

# DB1 è½®è¯¢é—´éš” (ç§’) - å¯åŠ¨æ€ä¿®æ”¹
_db1_interval: float = 0.5  # é»˜è®¤0.5sï¼Œå¯é€šè¿‡é…ç½®ä¿®æ”¹ä¸º0.2s

# æ‰¹é‡å†™å…¥ç¼“å­˜ (ä¸æ—§æ¶æ„ä¿æŒä¸€è‡´)
_arc_buffer_count = 0
_arc_batch_size = 20  #  DB1: 20æ¬¡è½®è¯¢åå†™å…¥ (0.5sÃ—20=10s)

_normal_buffer_count = 0
_normal_batch_size = 30  # ğŸ“Š DB32: 30æ¬¡è½®è¯¢åå†™å…¥ (0.5sÃ—30=15s)

_valve_buffer_count = 0
_valve_batch_size = 30  #  Valve: 30æ¬¡è½®è¯¢åå†™å…¥ (0.5sÃ—30=15s)


# ============================================================
# 1: æ‰¹é‡å†™å…¥å‡½æ•°æ¨¡å—
# ============================================================
async def _flush_arc_buffer():
    """æ‰¹é‡å†™å…¥ DB1 å¼§æµå¼§å‹ç¼“å­˜"""
    from backend.services.polling_data_processor import flush_arc_buffer
    await flush_arc_buffer()


async def _flush_normal_buffer():
    """æ‰¹é‡å†™å…¥ DB32/é‡é‡ç¼“å­˜"""
    from backend.services.polling_data_processor import flush_normal_buffer
    await flush_normal_buffer()


async def _flush_valve_buffer():
    """æ‰¹é‡å†™å…¥è¶é˜€å¼€åº¦ç¼“å­˜"""
    from backend.services.db32.valve_calculator import flush_valve_openness_buffers
    await flush_valve_openness_buffers()


# ============================================================
# 2: çŠ¶æ€æŸ¥è¯¢å‡½æ•°æ¨¡å—
# ============================================================
def get_polling_loops_status() -> dict:
    """è·å–æ‰€æœ‰è½®è¯¢å¾ªç¯çš„çŠ¶æ€
    
    Returns:
        dict: {
            'db1_running': bool,
            'db32_running': bool,
            'status_running': bool,
            'db1_interval': float
        }
    """
    return {
        'db1_running': _db1_running,
        'db32_running': _db32_running,
        'status_running': _status_running,
        'db1_interval': _db1_interval
    }


# ============================================================
# 3: DB1 å¼§æµå¼§å‹è½®è¯¢æ¨¡å— (å¯å˜é€Ÿ)
# ============================================================
async def _db1_arc_polling_loop(
    parser,
    process_func,
    is_mock: bool = False
):
    """DB1 å¼§æµå¼§å‹è½®è¯¢ (å¯å˜é€Ÿ: 5s -> 0.5s)
    
    Args:
        parser: DB1 è§£æå™¨
        process_func: æ•°æ®å¤„ç†å‡½æ•°
        is_mock: æ˜¯å¦ Mock æ¨¡å¼
    """
    global _db1_interval, _arc_buffer_count, _arc_batch_size
    poll_count = 0
    error_count = 0  # è¿ç»­é”™è¯¯è®¡æ•°å™¨
    MAX_ERROR_COUNT = 10  # æœ€å¤§é”™è¯¯æ¬¡æ•°ï¼Œè¶…è¿‡åå›ºå®š30s
    FIXED_WAIT_TIME = 30  # å›ºå®šç­‰å¾…æ—¶é—´ï¼ˆç§’ï¼‰
    
    logger.info(f"DB1 å¼§æµå¼§å‹è½®è¯¢å·²å¯åŠ¨ (åˆå§‹é—´éš”: {_db1_interval}s)")
    
    if not is_mock:
        plc = get_plc_manager()
        db_number = parser.get_db_number() if parser else 1
        db_size = parser.get_total_size() if parser else 182
    
    while _db1_running:
        try:
            poll_count += 1
            
            if is_mock:
                # Mock æ¨¡å¼: ç”Ÿæˆéšæœºæ•°æ®
                from backend.services.polling_data_generator import generate_mock_db1_data
                db1_data = generate_mock_db1_data()
            else:
                # PLC æ¨¡å¼: è¯»å–çœŸå®æ•°æ®
                if not plc.is_connected():
                    plc.connect()
                
                result = plc.read_db(db_number, 0, db_size)
                if isinstance(result, (tuple, list)) and len(result) == 2:
                    db1_data, err = result
                else:
                    db1_data = None
                
                if not db1_data:
                    await asyncio.sleep(1)
                    continue
            
            # å¤„ç†æ•°æ® (è·å–å½“å‰æ‰¹æ¬¡å·)
            from backend.services.polling_service import get_batch_info
            batch_info = get_batch_info()
            current_batch = batch_info.get('batch_code', '')  # æ²¡æœ‰æ‰¹æ¬¡å·æ—¶ä¼ ç©ºå­—ç¬¦ä¸²
            
            # æ— è®ºæ˜¯å¦å†¶ç‚¼ï¼Œéƒ½å¤„ç†æ•°æ®ï¼ˆæ›´æ–°å®æ—¶ç¼“å­˜ï¼‰
            # process_arc_data å†…éƒ¨ä¼šåˆ¤æ–­ï¼šæœ‰æ‰¹æ¬¡å·æ—¶å†™å…¥å†å²æ•°æ®åº“ï¼Œæ— æ‰¹æ¬¡å·æ—¶åªæ›´æ–°ç¼“å­˜
            process_func(db1_data, current_batch)
            
            # æ‰¹é‡å†™å…¥é€»è¾‘
            _arc_buffer_count += 1
            if _arc_buffer_count >= _arc_batch_size:
                await _flush_arc_buffer()
                _arc_buffer_count = 0
            
            # æˆåŠŸåé‡ç½®é”™è¯¯è®¡æ•°å™¨
            error_count = 0
            
            # åŠ¨æ€é—´éš” (å¯è¢«å¤–éƒ¨ä¿®æ”¹)
            await asyncio.sleep(_db1_interval)
            
        except asyncio.CancelledError:
            break
        except Exception as e:
            error_count += 1
            
            # 10æ¬¡å¤±è´¥åï¼Œå›ºå®šç­‰å¾…30ç§’
            if error_count >= MAX_ERROR_COUNT:
                logger.error(f"DB1 è½®è¯¢å¼‚å¸¸ (ç¬¬{error_count}æ¬¡ï¼Œå·²è¾¾ä¸Šé™): {e}")
                if error_count == MAX_ERROR_COUNT:
                    logger.warning(f"DB1 è¿ç»­å¤±è´¥ {MAX_ERROR_COUNT} æ¬¡ï¼Œåç»­æ¯æ¬¡å›ºå®šç­‰å¾… {FIXED_WAIT_TIME}s")
                await asyncio.sleep(FIXED_WAIT_TIME)
            else:
                # å‰10æ¬¡ä½¿ç”¨æŒ‡æ•°é€€é¿
                wait_time = min(FIXED_WAIT_TIME, 2 ** min(error_count - 1, 4))
                logger.error(f"DB1 è½®è¯¢å¼‚å¸¸ (ç¬¬{error_count}æ¬¡): {e}")
                if error_count <= 3:
                    logger.error(traceback.format_exc())
                await asyncio.sleep(wait_time)
    
    logger.info("DB1 å¼§æµå¼§å‹è½®è¯¢å·²åœæ­¢")


# ============================================================
# 4: DB32 ä¼ æ„Ÿå™¨è½®è¯¢æ¨¡å— (å›ºå®š 0.5s)
# ============================================================
async def _db32_sensor_polling_loop(
    parser,
    process_func,
    db18_parser,
    db19_parser,
    process_hopper_plc_func,
    is_mock: bool = False
):
    """DB32 ä¼ æ„Ÿå™¨ + æ–™ä»“ PLC æ•°æ®è½®è¯¢ (å›ºå®š 0.5s)
    
    Args:
        parser: DB32 è§£æå™¨
        process_func: æ•°æ®å¤„ç†å‡½æ•°
        db18_parser: DB18 è§£æå™¨
        db19_parser: DB19 è§£æå™¨
        process_hopper_plc_func: æ–™ä»“ PLC æ•°æ®å¤„ç†å‡½æ•°
        is_mock: æ˜¯å¦ Mock æ¨¡å¼
    """
    global _normal_buffer_count, _normal_batch_size, _valve_buffer_count, _valve_batch_size
    poll_count = 0
    error_count = 0  # è¿ç»­é”™è¯¯è®¡æ•°å™¨
    MAX_ERROR_COUNT = 10  # æœ€å¤§é”™è¯¯æ¬¡æ•°ï¼Œè¶…è¿‡åå›ºå®š30s
    FIXED_WAIT_TIME = 30  # å›ºå®šç­‰å¾…æ—¶é—´ï¼ˆç§’ï¼‰
    interval = 0.5  # å›ºå®š 0.5s (1ç§’2æ¬¡è½®è¯¢)
    
    logger.info(f"DB32 ä¼ æ„Ÿå™¨è½®è¯¢å·²å¯åŠ¨ (é—´éš”: {interval}s)")
    
    if not is_mock:
        plc = get_plc_manager()
        db_number = parser.get_db_number() if parser else 32
        db_size = parser.get_total_size() if parser else 29
    
    while _db32_running:
        try:
            poll_count += 1
            
            # 1. è¯»å– DB32 ä¼ æ„Ÿå™¨æ•°æ®
            if is_mock:
                from backend.services.polling_data_generator import generate_mock_db32_data
                db32_data = generate_mock_db32_data()
            else:
                if not plc.is_connected():
                    plc.connect()
                
                result = plc.read_db(db_number, 0, db_size)
                if isinstance(result, (tuple, list)) and len(result) == 2:
                    db32_data, err = result
                else:
                    db32_data = None
                
                if not db32_data:
                    await asyncio.sleep(1)
                    continue
            
            process_func(db32_data)
            
            # 2. è¯»å–æ–™ä»“ PLC æ•°æ® (DB18 + DB19 + QåŒº + IåŒº)
            # 2.1 è¯»å– DB18 (æ–™ä»“é‡é‡ã€æœ¬æ¬¡æ’æ–™é‡é‡ã€ä¸Šé™å€¼)
            db18_data = None
            if is_mock:
                from backend.services.polling_data_generator import generate_mock_db18_data
                db18_data = generate_mock_db18_data()
            else:
                try:
                    if db18_parser:
                        db18_number = db18_parser.get_db_number()
                        db18_size = db18_parser.get_total_size()
                        result = plc.read_db(db18_number, 0, db18_size)
                        if isinstance(result, (tuple, list)) and len(result) == 2:
                            db18_data, err = result
                except Exception as db18_err:
                    logger.debug(f"è¯»å– DB18 å¤±è´¥: {db18_err}")
                
            # 2.2 è¯»å– DB19 (æ’æ–™é‡é‡å¾…è¯»å–æ ‡å¿—)
            db19_data = None
            if is_mock:
                from backend.services.polling_data_generator import generate_mock_db19_data
                db19_data = generate_mock_db19_data()
            else:
                try:
                    if db19_parser:
                        db19_number = db19_parser.get_db_number()
                        db19_size = db19_parser.get_total_size()
                        result = plc.read_db(db19_number, 0, db19_size)
                        if isinstance(result, (tuple, list)) and len(result) == 2:
                            db19_data, err = result
                except Exception as db19_err:
                    logger.debug(f"è¯»å– DB19 å¤±è´¥: {db19_err}")
            
            # 2.3 è¯»å– QåŒºä¿¡å· (Q3.7 æ’æ–™, Q4.0 è¦æ–™)
            q_data = None
            if is_mock:
                from backend.services.polling_data_generator import generate_mock_q_data
                q_data = generate_mock_q_data()
            else:
                try:
                    q_data, q_err = plc.read_output_area(3, 2)  # è¯»å– Q3, Q4
                except Exception as q_err:
                    logger.debug(f"è¯»å– QåŒºå¤±è´¥: {q_err}")
            
            # 2.4 è¯»å– IåŒºä¿¡å· (I4.6 ä¾›æ–™åé¦ˆ)
            i_data = None
            if is_mock:
                from backend.services.polling_data_generator import generate_mock_i_data
                i_data = generate_mock_i_data()
            else:
                try:
                    i_data, i_err = plc.read_input_area(4, 1)  # è¯»å– I4
                except Exception as i_err:
                    logger.debug(f"è¯»å– IåŒºå¤±è´¥: {i_err}")
                
            # 2.5 å¤„ç†æ–™ä»“ PLC æ•°æ®
            from backend.services.polling_service import get_batch_info
            batch_info = get_batch_info()
            current_batch = batch_info.get('batch_code', '')
            is_smelting = batch_info.get('is_smelting', False)
            
            # ä¿®å¤: æ— è®ºæ˜¯å¦å†¶ç‚¼ï¼Œéƒ½å¤„ç†æ–™ä»“æ•°æ®ï¼ˆæ›´æ–°å®æ—¶çŠ¶æ€ï¼‰
            # åªæœ‰åœ¨å†¶ç‚¼çŠ¶æ€æ—¶æ‰å†™å…¥å†å²æ•°æ®åº“
            if db18_data and db19_data:
                process_hopper_plc_func(
                    db18_data=db18_data,
                    db19_data=db19_data,
                    q_data=q_data,
                    i_data=i_data,
                    batch_code=current_batch  # æ— æ‰¹æ¬¡å·æ—¶ä¼ ç©ºå­—ç¬¦ä¸²
                )
            
            # æ‰¹é‡å†™å…¥é€»è¾‘ (æ¯15ç§’å†™ä¸€æ¬¡: 0.5sÃ—30=15s)
            _normal_buffer_count += 1
            if _normal_buffer_count >= _normal_batch_size:
                await _flush_normal_buffer()
                _normal_buffer_count = 0
            
            # è¶é˜€å¼€åº¦æ‰¹é‡å†™å…¥é€»è¾‘ (æ¯15ç§’å†™ä¸€æ¬¡: 0.5sÃ—30=15s)
            _valve_buffer_count += 1
            if _valve_buffer_count >= _valve_batch_size:
                await _flush_valve_buffer()
                _valve_buffer_count = 0
            
            # æˆåŠŸåé‡ç½®é”™è¯¯è®¡æ•°å™¨
            error_count = 0
            
            await asyncio.sleep(interval)
            
        except asyncio.CancelledError:
            break
        except Exception as e:
            error_count += 1
            
            # 10æ¬¡å¤±è´¥åï¼Œå›ºå®šç­‰å¾…30ç§’
            if error_count >= MAX_ERROR_COUNT:
                logger.error(f"DB32 è½®è¯¢å¼‚å¸¸ (ç¬¬{error_count}æ¬¡ï¼Œå·²è¾¾ä¸Šé™): {e}")
                if error_count == MAX_ERROR_COUNT:
                    logger.warning(f"DB32 è¿ç»­å¤±è´¥ {MAX_ERROR_COUNT} æ¬¡ï¼Œåç»­æ¯æ¬¡å›ºå®šç­‰å¾… {FIXED_WAIT_TIME}s")
                await asyncio.sleep(FIXED_WAIT_TIME)
            else:
                # å‰10æ¬¡ä½¿ç”¨æŒ‡æ•°é€€é¿
                wait_time = min(FIXED_WAIT_TIME, 2 ** min(error_count - 1, 4))
                logger.error(f"DB32 è½®è¯¢å¼‚å¸¸ (ç¬¬{error_count}æ¬¡): {e}")
                if error_count <= 3:
                    logger.error(traceback.format_exc())
                await asyncio.sleep(wait_time)
    
    logger.info("DB32 ä¼ æ„Ÿå™¨è½®è¯¢å·²åœæ­¢")


# ============================================================
# 5: DB30/DB41 çŠ¶æ€è½®è¯¢æ¨¡å— (å›ºå®š 5s, ä»…ç¼“å­˜)
# ============================================================
async def _status_polling_loop(
    db30_parser,
    db41_parser,
    process_db30_func,
    process_db41_func,
    is_mock: bool = False
):
    """DB30/DB41 çŠ¶æ€è½®è¯¢ (å›ºå®š 5s, ä»…ç¼“å­˜)
    
    Args:
        db30_parser: DB30 è§£æå™¨
        db41_parser: DB41 è§£æå™¨
        process_db30_func: DB30 å¤„ç†å‡½æ•°
        process_db41_func: DB41 å¤„ç†å‡½æ•°
        is_mock: æ˜¯å¦ Mock æ¨¡å¼
    """
    poll_count = 0
    error_count = 0  # è¿ç»­é”™è¯¯è®¡æ•°å™¨
    MAX_ERROR_COUNT = 10  # æœ€å¤§é”™è¯¯æ¬¡æ•°ï¼Œè¶…è¿‡åå›ºå®š30s
    FIXED_WAIT_TIME = 30  # å›ºå®šç­‰å¾…æ—¶é—´ï¼ˆç§’ï¼‰
    interval = 5.0  # å›ºå®š 5s
    
    logger.info(f"çŠ¶æ€è½®è¯¢å·²å¯åŠ¨ (DB30+DB41, é—´éš”: {interval}s)")
    
    if not is_mock:
        plc = get_plc_manager()
        db30_number = db30_parser.get_db_number() if db30_parser else 30
        db30_size = db30_parser.get_total_size() if db30_parser else 40
        db41_number = db41_parser.get_db_number() if db41_parser else 41
        db41_size = db41_parser.get_total_size() if db41_parser else 28  # 7è®¾å¤‡Ã—4å­—èŠ‚=28
    
    while _status_running:
        try:
            poll_count += 1
            
            # 1. è¯»å– DB30 é€šä¿¡çŠ¶æ€
            if is_mock:
                from backend.services.polling_data_generator import generate_mock_db30_data
                db30_data = generate_mock_db30_data()
            else:
                if not plc.is_connected():
                    plc.connect()
                
                result = plc.read_db(db30_number, 0, db30_size)
                if isinstance(result, (tuple, list)) and len(result) == 2:
                    db30_data, err = result
                else:
                    db30_data = None
            
            if db30_data:
                process_db30_func(db30_data)
            
            # 2. è¯»å– DB41 æ•°æ®çŠ¶æ€
            if is_mock:
                from backend.services.polling_data_generator import generate_mock_db41_data
                db41_data = generate_mock_db41_data()
            else:
                result = plc.read_db(db41_number, 0, db41_size)
                if isinstance(result, (tuple, list)) and len(result) == 2:
                    db41_data, err = result
                else:
                    db41_data = None
            
            if db41_data:
                process_db41_func(db41_data)
            
            # æˆåŠŸåé‡ç½®é”™è¯¯è®¡æ•°å™¨
            error_count = 0
            
            await asyncio.sleep(interval)
            
        except asyncio.CancelledError:
            break
        except Exception as e:
            error_count += 1
            
            # 10æ¬¡å¤±è´¥åï¼Œå›ºå®šç­‰å¾…30ç§’
            if error_count >= MAX_ERROR_COUNT:
                logger.error(f"çŠ¶æ€è½®è¯¢å¼‚å¸¸ (ç¬¬{error_count}æ¬¡ï¼Œå·²è¾¾ä¸Šé™): {e}")
                if error_count == MAX_ERROR_COUNT:
                    logger.warning(f"çŠ¶æ€è½®è¯¢è¿ç»­å¤±è´¥ {MAX_ERROR_COUNT} æ¬¡ï¼Œåç»­æ¯æ¬¡å›ºå®šç­‰å¾… {FIXED_WAIT_TIME}s")
                await asyncio.sleep(FIXED_WAIT_TIME)
            else:
                # å‰10æ¬¡ä½¿ç”¨æŒ‡æ•°é€€é¿
                wait_time = min(FIXED_WAIT_TIME, 2 ** min(error_count - 1, 4))
                logger.error(f"çŠ¶æ€è½®è¯¢å¼‚å¸¸ (ç¬¬{error_count}æ¬¡): {e}")
                if error_count <= 3:
                    logger.error(traceback.format_exc())
                await asyncio.sleep(wait_time)
    
    logger.info("çŠ¶æ€è½®è¯¢å·²åœæ­¢")


# ============================================================
# å¯åŠ¨/åœæ­¢å‡½æ•° (ä¾› main.py è°ƒç”¨)
# ============================================================
async def start_all_polling_loops():
    """å¯åŠ¨æ‰€æœ‰è½®è¯¢ä»»åŠ¡ (è‡ªåŠ¨å¯åŠ¨)"""
    global _db1_task, _db32_task, _status_task
    global _db1_running, _db32_running, _status_running
    global _db1_interval
    
    from backend.services.polling_data_processor import (
        init_parsers,
        get_parsers,
        process_arc_data,
        process_modbus_data,
        process_status_data,
        process_db41_data,
        process_hopper_plc_data,
    )
    
    # åˆå§‹åŒ–è§£æå™¨
    init_parsers()
    
    # è·å–è§£æå™¨
    db1_parser, modbus_parser, status_parser, db41_parser, db18_parser, db19_parser = get_parsers()
    
    # ä»é…ç½®ç®¡ç†å™¨è·å–è½®è¯¢é—´éš”
    from backend.config.polling_config import get_polling_config
    polling_config = get_polling_config()
    _db1_interval = polling_config.get_polling_interval()
    
    # æ³¨å†Œé…ç½®å˜åŒ–å›è°ƒ
    def on_polling_speed_changed(speed):
        global _db1_interval
        _db1_interval = polling_config.get_polling_interval()
        logger.info(f"DB1 è½®è¯¢é€Ÿåº¦å·²æ›´æ–°: {speed} (é—´éš”: {_db1_interval}s)")
    
    polling_config.register_callback(on_polling_speed_changed)
    
    # å¯åŠ¨æ ‡å¿—
    _db1_running = True
    _db32_running = True
    _status_running = True
    
    is_mock = settings.mock_mode
    mode_text = "Mock" if is_mock else "PLC"
    
    logger.info("=" * 60)
    logger.info(f"å¯åŠ¨ä¸‰é€Ÿè½®è¯¢æ¶æ„ ({mode_text} æ¨¡å¼)")
    logger.info("   DB1 å¼§æµå¼§å‹: 0.5s (å›ºå®šé«˜é€Ÿ)")
    logger.info("   DB32 ä¼ æ„Ÿå™¨: 0.5s (é«˜é¢‘, å«å†·å´æ°´æµé‡è®¡ç®—)")
    logger.info("   æ–™ä»“ PLC: 0.5s (DB18+DB19+QåŒº+IåŒº)")
    logger.info("   DB30/DB41 çŠ¶æ€: 5s (å›ºå®š)")
    logger.info("=" * 60)
    
    # åˆ›å»ºä»»åŠ¡
    _db1_task = asyncio.create_task(_db1_arc_polling_loop(
        db1_parser,
        process_arc_data,
        is_mock=is_mock
    ))
    
    _db32_task = asyncio.create_task(_db32_sensor_polling_loop(
        modbus_parser,
        process_modbus_data,
        db18_parser,
        db19_parser,
        process_hopper_plc_data,
        is_mock=is_mock
    ))
    
    _status_task = asyncio.create_task(_status_polling_loop(
        status_parser,
        db41_parser,
        process_status_data,
        process_db41_data,
        is_mock=is_mock
    ))


async def stop_all_polling_loops():
    """åœæ­¢æ‰€æœ‰è½®è¯¢ä»»åŠ¡"""
    global _db1_task, _db32_task, _status_task
    global _db1_running, _db32_running, _status_running
    
    _db1_running = False
    _db32_running = False
    _status_running = False
    
    tasks = [_db1_task, _db32_task, _status_task]
    for task in tasks:
        if task:
            task.cancel()
            try:
                await task
            except asyncio.CancelledError:
                pass
    
    logger.info("æ‰€æœ‰è½®è¯¢ä»»åŠ¡å·²åœæ­¢")


def switch_db1_speed(high_speed: bool):
    """åˆ‡æ¢ DB1 è½®è¯¢é€Ÿåº¦
    
    Args:
        high_speed: True=0.5s (å†¶ç‚¼ä¸­), False=5s (ç©ºé—²)
    """
    global _db1_interval
    
    if high_speed:
        _db1_interval = 0.5
        logger.info("DB1 è½®è¯¢åˆ‡æ¢åˆ°é«˜é€Ÿæ¨¡å¼ (0.5s)")
    else:
        _db1_interval = 5.0
        logger.info("DB1 è½®è¯¢åˆ‡æ¢åˆ°ä½é€Ÿæ¨¡å¼ (5.0s)")


def get_polling_loops_status():
    """è·å–è½®è¯¢ä»»åŠ¡çŠ¶æ€"""
    return {
        "db1_running": _db1_running,
        "db1_interval": _db1_interval,
        "db32_running": _db32_running,
        "status_running": _status_running,
    }
